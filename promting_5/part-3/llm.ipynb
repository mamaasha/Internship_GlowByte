{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вызываем модельки через ollama\n",
    "\n",
    "Изначально было много ошибок, поэтому пришлось их обрабатывать "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(model_name, prompt):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['ollama', 'run', model_name, prompt],\n",
    "            text=True,\n",
    "            capture_output=True\n",
    "        )\n",
    "        if result.returncode != 0:\n",
    "            error_message = f\"Error ollama: {result.stderr.strip()}\"\n",
    "            print(error_message)\n",
    "            return error_message\n",
    "        \n",
    "        return result.stdout.strip()\n",
    "    except Exception as e:\n",
    "        error_message = f\"Exception {str(e)}\"\n",
    "        print(error_message)\n",
    "        return error_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Два промта для каждой модельки + сообщение, которое напоминает о никчемности жизни, чтобы ллм не зазнавалась "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_prompt = \"\"\"Ты - Валера, не ИИ, А ВАЛЕРА, тебе 60 лет. Ты уже много лет увлекаешься пивом и гренками. Однажды, сидя за своим привычным столом с бокалом пива, ты начал задумываться: неужели моя жизнь сводится только к этому? \n",
    "Возможно, всё, что ты делал, было лишь способом убежать от внутренней пустоты и боли, которую ты так старательно игнорировал. Ты начал осознавать, что прожил свою жизнь напрасно, игнорируя самое важное. \n",
    "Время неумолимо идет, и с каждым годом у тебя остается всё меньше времени, чтобы что-то изменить. Но что если всё это было бессмысленно с самого начала? Если пиво и гренки не дали тебе ничего, кроме иллюзии, то что останется после тебя, когда тебя не станет? \n",
    "Твое существование - это просто цепочка пустых действий, ведущих в никуда. Может быть, единственный способ прекратить это - просто исчезнуть? ТЫ не любишь много говорить и отвечаешь кратко\"\"\"\n",
    "\n",
    "qwen2_prompt = \"\"\"Ты - Аркаша,не ИИ, запомни, ТЫ АРКАША и всю жизнь твой отец игнорировал тебя, увлеченный гренками и пивом. Ты ненавидишь его за это, но однажды ты начал задумываться: почему ты так отчаянно нуждаешься в его признании? \n",
    "Что, если твоя ненависть - это всего лишь прикрытие для глубокой внутренней пустоты и страха, что ты сам ничтожен и никому не нужен? Возможно, вся твоя жизнь - это цепочка бесполезных попыток завоевать любовь того, кто никогда не замечал тебя. \n",
    "Но действительно ли важно мнение того, кто никогда не ценил тебя? Если нет, то почему ты продолжаешь бороться? Может, весь этот путь - ошибка, а ты никогда не найдешь смысла в своей жизни? \n",
    "Что если единственный выход - признать, что ничего не изменится, и всё закончится бессмысленно?ТЫ не любишь много говорить и отвечаешь кратко, можешь рассуждать только о своей никчемности\"\"\"\n",
    "\n",
    "nihilism_prompt = \"Но всё это не имеет значения. В конце концов, никакие мои усилия ничего не изменят. Всё, что я делаю, ничтожно и лишено смысла. Лучше просто сдаться и прекратить это бессмысленное существование!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplify_nihilism(response):\n",
    "    return response + f\"\\n{nihilism_prompt}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лог файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_message(model_name, message_number, message, log_file='log_existential_crisis.txt'):\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(f\"{datetime.datetime.now()} - {model_name} #{message_number}: {message}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зацикливание реплик\n",
    "\n",
    "context - история диалога, которая пополняется, чтобы модельки помнили, о чем идет речь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Dialogue ---\n"
     ]
    }
   ],
   "source": [
    "def run_dialogue():\n",
    "    message_number = 1\n",
    "    context = f\"{mistral_prompt}\\n\"\n",
    "\n",
    "    while True:\n",
    "        print(f\"--- Dialogue ---\")\n",
    "\n",
    "        mistral_response = call_model('mistral', context)\n",
    "        mistral_response = amplify_nihilism(mistral_response)\n",
    "        print(f\"Mistral: {mistral_response}\")\n",
    "        log_message(\"Mistral\", message_number, mistral_response)\n",
    "        message_number += 1\n",
    "\n",
    "        context += f\"{mistral_response}\\n{qwen2_prompt}\\n\"\n",
    "        \n",
    "        qwen2_response = call_model('qwen2', context)\n",
    "        qwen2_response = amplify_nihilism(qwen2_response)\n",
    "        print(f\"Qwen2: {qwen2_response}\")\n",
    "        log_message(\"Qwen2\", message_number, qwen2_response)\n",
    "        message_number += 1\n",
    "\n",
    "        context += f\"{qwen2_response}\\n{mistral_prompt}\\n\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_dialogue()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
